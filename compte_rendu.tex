\documentclass{article}
\usepackage[frenchb]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{yhmath}
\usepackage{stmaryrd}
\usepackage{fancyhdr}
\usepackage{bussproofs}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{tikz-qtree}
\usepackage{ulem}
\pagestyle{fancy}
\title{Approche probabiliste pour le TALN}
\author{Arthur Lapraye\\Clément Beysson}
\date{\today}
\begin{document}
\maketitle
%\newpage
\tableofcontents
\newpage
\section{Introduction}
Le but de ce projet est d'étudier les POS taggers sous plusieurs angles.

Dans ce cadre, nous commencerons par traiter la qualité intrinsèque de divers algorithmes de POS tagging, chacun étant évalué sur l'ensemble de tags complet du corpus Tiger ainsi que sur l'esemble réduit des tags universaux.

Toujours dans ce but, nous génèrerons des matrices de confusion dans le but de vérifier si certains tag ne seraient pas superflus car confondus avec d'autres. Cette similarité entre tags peut aussi être estimée à l'aide d'une distance entre vecteurs de poids.

%C'est pas les POS tagger qui sont générés, ce sont les tags, non ?
Pour finir, nous utiliserons les POS tagger générés dans un analyseur en dépendance. Ainsi, nous pourrons évaluer nos divers algorithmes et paramètres et optenir leur qualité extrinsèque vis à vis de cette tache.

\section{Entraînement d'un POS tagger}

Pour tous nos POS tagger, nous avons utilisé le corpus Tiger. $10\%$ des phrases de ce corpus sont extraites aléatoirement pour servir de test, les $90\%$ restantes serviront à l'entrainement.

Pour toute la suite, soit $S = w_1.w_2...w_n$ la phrase à analyser, composée dans l'ordre des mots $(w_i)_{i\in[1,n]}$.

\subsection{Classe majoritaire par forme}

Cette méthode excessivement naïve sera notre baseline. Il s'agit de prédir pour chaque mot-forme le tag avec lequel il est le plus souvent associé dans le corpus. Il s'agit donc d'un modèle de Markov d'ordre 0.

Pour l'entrainement, on compte le nombre d'occurence de chaque couple $(mot,tag\_gold)$ dans le corpus. Ces comptes seront nos paramètres pour la prédiction.

$$\forall i \in [1,n] . tag(w_i) = argmax_{t \in Tag} \#(w_i,t)$$

\subsection{Chemin localement optimal}

Nous avons souhaité tester un intermédiaire entre un modèle de Markov d'ordre 0 et celui d'ordre 1. Dans ce modèle, on cherche à prédire séquentiellement les tag des mots d'une phrase uniquement à l'aide du mot lui même et du tag déjà prédit pour le mot précédent.

Pour l'entrainement, on compte le nombre d'occurence des triplets $(mot,tag\_gold,tag\_gold\_precedent)$, sachant que $tag\_gold\_precedent$ peut être le tag artificiel $debut\_de\_phrase$, dans le corpus. Ces comptes seront nos paramètres pour la prédiction.

On considère que $w_0$ a pour tag $debut\_de\_phrase$.

$$\forall i \in [1,n] . tag (w_i) = argmax_{t \in Tag} \#(w_i,t,tag(w_{i-1}))$$

\subsection{HMM}

Il s'agit ici d'un modèle de Markov d'ordre 1. Ce modèle cherche à prédire les tags de tous les mots d'une phrase simultanément en sachant que la probabilité d'associer un tag à un mot donné ne dépend, comme précédement, que du mot et du tag précédent.

Pour l'entrainement, on procède exactement comme précédement pour obtenir les même paramètres.

$$\forall w \in Voc . \forall t_1,t_2 \in Tag^2 . prob(w,t_1,t_2) = log_2 \left( \frac{\#(w,t_1,t_2)}{\underset{t \in Tag}{\Sigma}\#(w,t,t_2)} \right) $$

$$\forall i \in [1,n] . tag(w_i) = \underset{t_i \in Tag}{argmax} \left( \underset{t_1,...,t_{i-1},t_{i+1},...,t_n \in Tag^{n-1}}{max} \left( \underset{j \in [1,n]}{\Sigma} prob(w_j,t_j,t_{j-1}) \right) \right)$$

\subsection{Perceptron}

Dans le modèle du perceptron, un mot dans le contexte de sa phrase est converti en un vecteur de dimension fixée contenant les informations jugées pertinentes le concernant, lui et son contexte. Chaque tag étant associé à une application multilinéaire sur un espace de même dimension, il suffit pour effectuer une prédiction d'appliquer ces applications au vecteur du mot et à prendre le tag donnant le meilleur score.

Pour l'entrainement, il faut apprendre ces applications. Or, une application multilinéaire vers un espace de dimension 1 n'est rien d'autre qu'un produit scalaire. Il faut donc apprendre des vecteurs.

On note $\overrightarrow{w}$ le vecteur représentatif du mot $w$ et de son contexte. De même, on note $\overrightarrow{t}$ le vecteur représentatif de l'application associée au tag $t$.

$$\forall i \in [1,n] . tag(w_i) = \underset{t \in Tag}{argmax}\overrightarrow{t}.\overrightarrow{w_i}$$

Cependant, plus que le nombre d'itération, c'est le choix des composantes des vecteurs de poids du perceptron qui impactent ses performances. Dans notre cas, nous avons choisit uniquement des composante binaire, indiquant la présence ou l'absence d'un attribut. ces attributs sont tout d'abord les mots eux même, mais aussi les deux et trois premiers lettres, ainsi que les deux et trois dernières lettres. Nous avons également ajouté les même informations sur les mots précédent et suivant dans la phrase.


\section{Précision intrinsèque}

La précision intrisèque est une mesure de la qualité d'un outil en lui même. Il s'agit de savoir si ses sorties sont conformes à ce qu'on attend de lui.

\subsection{Critère de précision}

Dans le cas d'un POStagger, le but de l'algorithme est d'être capable d'étiqueter correctement les mots d'une phrase. De plus, comme il s'agit d'apprentissage supervisé, nous disposons d'un corpus étiqueté dans lequel chaque mot s'est vu attribué un tag, considéré comme bon.

Dans ces conditions, nous allons utilisé la partie teste du corpus ($10\%$ aléatoirement séléctionnés) et comparer la réponse de notre POStagger avec les tag gold de cette partie.

On calcule donc la précision $Pr_{Tag,Algo,Test}$ d'un algorithme $Algo$ avec un tagset $Tag$ sur un corpus de teste donné avec :

$$Pr_{Tag,Algo,Test} = \frac{\underset{mot \in Test}{\Sigma} \delta_{Algo(mot) , gold(mot)}}{\underset{mot \in Test}{\Sigma} 1}$$

la précision intrinsèque de notre modèle sera d'autant plus grande que cette proportion de mot bien taggé sera grande.

\subsection{Comparaisons}

Voici les précisions experimentales obtenues ;

$$
\begin{array}{c c c}
&\text{Universel}&\text{Riche}\\
\text{Classe majoritaire par forme}&90\%&89\%\\
\text{Chemin localement optimal}&87\%&80\%\\
\text{HMM}&95\%&94\%\\
\text{Perceptron}&??\%&??\%\\
\end{array}
$$

\subsubsection{Comparaison entres algorithmes}

Dans un Premier temps, rappelons que l'algorithme de classe majoritaire par forme est notre baseline. Ainsi, on se rend compte que l'algorithme de chemin localement optimal obtient une précision sous notre baseline, ce qui est contraire à nos attente. En effet, ce modèle nous semblait moins naïf et plus riche en informations. Nous n'étudierons plus ce modèle dans la suite.

De leur côté, le perceptron et le HMM sont tous les deux meilleur que notre baseline. Le perceptron est légèrement meilleur, et plus on l'itère, plus il est performant. Cependant, en terme de temps d'execution, le HMM est de très loin plus rapide. Il ne s'agit pas d'un critère de qualité théorique, mais dans la pratique il faut voir si le gain en précision vaut ce cout en temps.

\subsubsection{Comparaison entres tagset}

On remarque, dans tous nos testes, que la précision est plus grande avec le tagset universel qu'avec le tagset riche. En poussant le raisonnement à l'extrème, avec un unique tag, on aurait une précision de $100\%$. On se rend compte assez rapidement que plus le tagset est restraint, plus la précision est grande pour un algorithme donné.

Il est donc inutil de chercher a optimiser un tagset selon le critère de sa précision intrinsèque, puisque l'optimal est le tag unique, et est sans le moindre doute totalement inutile.

\section{Précision extrinsèque}

La précision extrisèque est une mesure de la qualité d'un outil dans le cadre de son utilisation par un autre outils. Il s'agit de savoir si ses sorties sont util pour amélioré la précision (intrinsèque ou extrinsèque) d'un autre outil.

Bien évidement, il n'est pas possible de donner la précision extrinsèque d'un outil, puisque celle de celui sui l'utilise entre en ligne de compte. La seule possibilité est de comparer les précision extrinsèque de divers paramétrage de notre outils, en fonction d'un même utilisateur.

\subsection{Critère de précision}

Pour comparer la précision extrinsèque de deux POStagger, nous utilisons un unique algorithme qui utilise ces tag (en l'occurence, un analyseur en dépendance) et nous comparons la précision intrinsèque des couples $(POStagger1,dépendences)$ et $(POStagger2,dépendences)$

\subsection{Comparaisons}

Voici les précisions experimentales obtenues ;

$$
\begin{array}{c c c}
&\text{Universel}&\text{Riche}\\
\text{Classe majoritaire par forme}&??\%&??\%\\
\text{HMM}&??\%&??\%\\
\text{Perceptron}&??\%&??\%\\
\end{array}
$$

\subsubsection{Comparaison entres algorithmes}

Nous observons une fois de plus que le perceptron est plus précis que le HMM, lui même meilleur que notre baseline. 

\subsubsection{Comparaison entres tagset}

\subsection{Améliorations}

\subsubsection{Matrice de confusion}

Cette matrice nous permet de voir si certains tag sont confondu avec d'autres. Cependant, il n'est pas possible de représenter ici la matrice $(52 \times 52)$ des tag riches. Nous exposerons donc ici seulement celles des tag universaux.

$$
\begin{array}{l|c|c|c|c|c|c|c|c|c|c|c|c}
\end{array}
$$

\subsubsection{Proximité vectorielle}
\section{Conclusion}
\end{document}
